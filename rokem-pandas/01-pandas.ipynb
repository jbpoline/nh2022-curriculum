{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01985e4-65a7-4fde-83e5-337acbb9fcb5",
   "metadata": {},
   "source": [
    "# Munging data with Pandas \n",
    "\n",
    "\n",
    "Data \"munging\" is the series of actions that we take to transform data that we are given from its raw form to something that we can process and understand. \n",
    "\n",
    "In neuroimaging, we can roughly divide this process into two steps: in the first, we work with the images that were collected in the scanner. This entails some image processing, some time-series analysis and so forth. In the second step, we might already be looking at features that have been extracted from the data and are abstracted away from the original images. For example, the size of each of a collection of brain regions in each of the subjects in a sample. The second kind of data can be organized into a *tabular* format. We will talk about desirable characteristics for this kind of data in a little bit, but let's start with a really simple example. Consider a dataset describing some fruit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507753de-8024-4719-be88-2590150ada12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = {\"UID\": [\"a101\", \"o101\", \"o102\", \"b101\"],\n",
    "         \"Kind\": [\"Apple\", \"Orange\", \"Orange\", \"Banana\"], \n",
    "         \"Price\": [0.1, 0.75, 0.84, 1.2],\n",
    "         \"Weight\": [200, 250, 280, 100],\n",
    "         \"Deliciousness\": [8, 5, 6, 10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a01c40-0b52-4d98-ad4c-6043a95abd2f",
   "metadata": {},
   "source": [
    "As a dictionary, these data would be hard to manipulate. For example, try writing code to display the average price of oranges. An altetnative would have been to store all this data as a Numpy array, but we also can't organize this very well into a numpy array, because it has mixed types and one dimension (the order of items in each list) means one thing, while the other (the different lists) means another thing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c17a3-00c9-4cdd-8ee4-8a63cb620bdc",
   "metadata": {},
   "source": [
    "Pandas (sure, it's an animal, but it also stands for \"panel data\", which is another name for tabular data) is a software library that helps do exactly these kinds of things with data like this. Over the years, it's become a real \"industry standard\" for work with these kinds of data and has become a dependency or interoperates well with many other software libraries that analyze, visualize and create such data. Including many neuroscience-specific software. You will see some of these examples here, and once you learn about Pandas, will start noticing this everywhere.\n",
    "\n",
    "Let's start by initializing a DataFrame, which is the workhorse object for Pandas data manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16a01a-7cf4-4c4f-92be-d51dd57b281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639bb4aa-1817-40f7-94ca-d99343695ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table = pd.DataFrame(fruit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffdf9b1",
   "metadata": {},
   "source": [
    "In Jupyter, we can show the data in nice tabular format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbfd60-0807-4a77-98f1-a1aaf29ede1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1256dbe2",
   "metadata": {},
   "source": [
    "We can also use the DataFrame to query the data, either by column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb77cb1-5838-4fd9-8c37-7052cc5d399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table[\"Kind\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4423da",
   "metadata": {},
   "source": [
    "Or by designating one of our columns as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeedef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table = fruit_table.set_index(\"UID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2286974",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def5953c",
   "metadata": {},
   "source": [
    "and using that to query the rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table.loc[\"a101\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ad7b3-992e-463d-92a8-0578b9cb2926",
   "metadata": {},
   "source": [
    "You can also combine these to query on rows and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ed78a-471f-4eab-bc33-46cd818766cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table.loc[\"a101\", \"Price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec09fb24-227d-40b3-82c5-e18a3be5b86a",
   "metadata": {},
   "source": [
    "And even slice on each dimension to get sub-tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44108a58-81a6-4d5b-905f-8ba6ae3a97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table.loc[\"a101\":\"o102\", \"Price\":\"Weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe8a3f-6c98-4da0-9721-a6572d42b859",
   "metadata": {},
   "source": [
    "There is another kind of indexer, `iloc` that will also give you a specific row based on its serial position in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4592dc-cda5-4751-a400-7b297433e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2994787-ace6-473c-886b-0d119d8dcf43",
   "metadata": {},
   "source": [
    "But maybe you can already come up with some ideas about why using this kind of indexing can be a bad idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cfdcc0-8151-4193-a955-6327c7eb68e5",
   "metadata": {},
   "source": [
    "## Computing with DataFrame objects\n",
    "\n",
    "Much like Numpy arrays, DataFrames have methods attached to them that let us do computations on the values stored in them. However, in contrast to Numpy arrays, averaging is typically (and per default) done column by column (because it wouldn't make sense to average price and weight, for example) and the DataFrame objects are aware of the fact that some of their columns may contain information that cannot be averaged, because it is not numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e74c3-8863-413e-9afd-aa4091425d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1411321-d7b8-4e82-ace7-ec23580915ec",
   "metadata": {},
   "source": [
    "We'll see other types of computations a bit further below, but let's "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e653f10-6948-4b5b-9021-7dd44d875966",
   "metadata": {},
   "source": [
    "## Selecting items in a DataFrame\n",
    "\n",
    "One of the operations that we often want to do with data is to filter it or select based on a particular attribute. For example, we mentioned the idea of computing the average price of oranges in this dataset.\n",
    "\n",
    "Let's parse this idea bit by bit. First, we'd like to find all the oranges in the `\"Kind\"` column. When we select a single column from the data, the return value is no longer a `DataFrame`. Instead, it's something that Pandas calls a `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510df11-f315-4a41-8a69-f6e502c2d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_kinds = fruit_table[\"Kind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d584e-3330-4a58-a0ab-b9ff8ecc4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fruit_kinds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746559b8-b9fb-46ad-ada4-c0e4ea3fe386",
   "metadata": {},
   "source": [
    "This kind of objects lends itself to Boolean operations. For example, comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97413319-601e-485a-b37f-dd7a17c79030",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_orange = fruit_kinds == \"Orange\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb37139-8a16-4411-af65-53e4cfcdb798",
   "metadata": {},
   "source": [
    "The result of this computation is another Pandas `Series` object, but this one has a Boolean datatype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f06d91-782a-407d-b25e-a5b5ba370616",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_orange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665da2d-68ae-4370-85fe-f5cf18ed8e13",
   "metadata": {},
   "source": [
    "In Numpy, we use Boolean arrays to index and select from other arrays of the same shape. In Pandas, we use Boolean Series to index and select on the rows of Pandas DataFrame objects. For example, the following gives us a table with only the Oranges from the original `fruit_table` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c655277-f06d-4e34-a38e-087238ac966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table[is_orange]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903a263-dead-4a71-8164-bc8a16b8c9a9",
   "metadata": {},
   "source": [
    "We can also do this in one fell swoop, without creating the intermediate objects, and you will often see code that looks like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc424eb-3dde-46f5-8c63-cf00fc8122b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orange_table = fruit_table[fruit_table[\"Kind\"] == \"Orange\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641e797-7976-4306-962e-3255a7599a38",
   "metadata": {},
   "source": [
    " We can proceed to calculate the average price of oranges from the new table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8a40d-f820-440c-b88a-c2852858581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orange_table[\"Price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88434c38-c5a3-486a-b39e-2205496b4b97",
   "metadata": {},
   "source": [
    "Or even in one call from the original table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c669e-c181-410c-9aad-18f7fadac023",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table[fruit_table[\"Kind\"] == \"Orange\"][\"Price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901649ab-1d0c-4310-9bb1-6e1def367fd8",
   "metadata": {},
   "source": [
    "### Computing with Series\n",
    "\n",
    "Because each Series does have a data type associated with it, you can do pretty sensible computations with it, such as multiplication by a scalar. For example, if we know that the \"Weight\" column is given in grams, we can convert all of the weights to Kilogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb12122-fae8-407e-8e8a-7f74220b7429",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_in_kg = fruit_table[\"Weight\"] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64758512-f2cf-41d9-a3b4-e1059f29297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_in_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b2c7a-367d-4642-bb89-988a0897dac3",
   "metadata": {},
   "source": [
    "Interestingly, we can make that into a new column in the existing table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73354af-cf53-41af-9065-fda60852e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table[\"Weight_kg\"] = fruit_table[\"Weight\"] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746c7e0-61bf-41bb-ab3e-ce3d2b21df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad78c5-dbda-423c-8a17-c8672e1d8ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ad07fb2-7c11-48cb-bfac-e520c82c0e05",
   "metadata": {},
   "source": [
    "And because they all have the same number of items, you can also do item-by-item computations between Series objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c6b37-0894-457d-9c2b-11416d8405c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table[\"Price_per_kg\"] = fruit_table[\"Price\"] / fruit_table[\"Weight_kg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf881e-7178-4c3a-9f53-5abb53751755",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f439366-4bb2-4917-a87a-b24fdfa1c81b",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "How would you compute a \"deliciousness per dollar\" index for these fruit?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3089dc1b-c619-40ac-b82c-b72e80c76edd",
   "metadata": {},
   "source": [
    "### Accessing data stored in files \n",
    "\n",
    "One of Pandas real super powers is the ability to read data from multiple different sources. \n",
    "\n",
    "So long as the data is stored in a way that can be interpreted as a table, Pandas can probably read it. This includes all kinds of proprietary formats (such as xls and stata files), and also all kinds of binary formats (if you like that kind of thing, check out the parquet file format for some high-efficiency ways of storing really large tables). \n",
    "\n",
    "Here, we'll look at some data stored in standard, text-based formats. The data we will look at comes from the ABIDE2 dataset and was extracted for this paper: \n",
    "\n",
    "> Bethlehem, R.A.I., Seidlitz, J., Romero-Garcia, R. et al. A normative modelling approach reveals age-atypical cortical thickness in a subgroup of males with autism spectrum disorder. Commun Biol 3, 486 (2020). https://doi.org/10.1038/s42003-020-01212-9\n",
    "\n",
    "ABIDE2 is a large data collection and sharing effort focused on measurements from individuals with autism and control subjects. Let's see what we get when we read the tsv file that contains ABIDE data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e3192-a8e0-4d8c-b855-b3558c411aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"/home/jovyan/shared/abide2/abide2.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fbac2-a4f3-4867-ae55-168eb5a070cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6354e8-f2de-4575-a7a3-8f82421e9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706563e-b27e-417e-a4b2-8fd62140b948",
   "metadata": {},
   "source": [
    "The table contains 1004 rows, corresponding to the 1004 subjects in the dataset. \n",
    "\n",
    "The six first columns contain information about each subject: a unique identifier, their age, age residuals relative to the site from which their data was collected (which we will not use here, but will come in handy later in the week, when we use it in the machine learning session), their sex, and whether they were diagnosed with autism (where 1 indicates an autism diagnosis and 2 indicates a control subject). \n",
    "\n",
    "The remaining 1440 columns contain structural brain features computed with Freesurfer: surface area (fsArea), volume (fsVol), cortical thickness (fsCT), and local gyrification (fsLGI). We have 360 * 4 features, for each of the 360 regions-of-interest in the Human Connectome Project’s multi-modal parcellation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c62e5-6d5a-4be7-8399-b7bea0a19cbe",
   "metadata": {},
   "source": [
    "When data are this big, it's sometimes useful to get a summary of the distributions of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb52197-cc21-4f9c-be11-051830f0d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20fe022-ecb4-448e-a9cc-f655c2a47a0c",
   "metadata": {},
   "source": [
    "In this case, we get some interesting information primarily about the age of the subjects. We also get a sense of the distribution among the two classes in `group` (is this data balanced?), but there are still a lot of columns to look at. Without worry about that too much for now, let's proceed to demonstrate some additional useful data management patterns accessible through Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc23de5-2dc8-40ff-bc1f-99193c498db9",
   "metadata": {},
   "source": [
    "## Split-apply-combine\n",
    "\n",
    "This pattern is very common and very useful. The idea is that we can split the data based on some feature, apply some kind of computation to each group and then combine all of the results into a new dataset. \n",
    "\n",
    "For example, a pretty obvious thing to do here would be to split or group the data by the `group` variable, and compute some statistics separately for each one of the groups. We could do this based on what we've seen so far -- logical indexing that selects one group after the other and does the operations we want to do on each group separately. But let's introduce a new way of doing this and some new functionality. \n",
    "\n",
    "### Groupby\n",
    "\n",
    "Each DataFrame object has a method `groupby`, which splits the data up internally according to the unique values of a column, or combination of columns. For example, we can ask the DataFrame to give us groups based on the `group` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5d9ae-958a-4317-94fc-7baea0b75796",
   "metadata": {},
   "outputs": [],
   "source": [
    "autism_groups = features.groupby(\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac68b2-ff46-410c-85bf-2c09aa1799b5",
   "metadata": {},
   "source": [
    "The resulting object is not a DataFrame! Instead, it's an object that is a little bit inscrutable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc09ed-f29d-43fb-ad3b-8d30d8c8a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "autism_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d2a6e-4851-497c-ae2c-48f3ad2e1f77",
   "metadata": {},
   "source": [
    "To make it more sensible, we have to keep going for a bit more. We've split the data. Next, we can apply a computation and combine back into a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08bd305-6195-4dde-bcea-18c1d04ae1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "autism_groups.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2afe54-1580-4b93-b7d9-ef5c5590dac7",
   "metadata": {},
   "source": [
    "This result is a DataFrame! And now, instead of individuals on each row, it has reduced the data down to means across each group. \n",
    "\n",
    "What if we want to explore more complex combinations? For example, all possible combinations of `group` and `sex`? This would already be pretty cumbersome using Series indexing that we saw above. But `groupby` makes it relatively straightforward:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632ec7e-c9e8-45d8-bf39-13580aef020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "autism_sex_groups = features.groupby([\"group\", \"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee1049-8860-42ab-b8f8-6c36e8813642",
   "metadata": {},
   "outputs": [],
   "source": [
    "autism_sex_means = autism_sex_groups.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768235a3-2961-4469-82a2-7fcdaadebcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "autism_sex_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc95d7e-2a9a-4eb3-a434-c985bdaf051c",
   "metadata": {},
   "source": [
    "The new object we get as a result of this computation is a DataFrame, but instead of one index that we can use to select from it, it has multiple levels of indexing (This is called a `MultiIndex`). The first one selects from the `group`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca3c8d-4632-44be-a63d-75883d5dc312",
   "metadata": {},
   "outputs": [],
   "source": [
    "autism_sex_means.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee74871-0249-4ee1-abb6-ba612fb06d68",
   "metadata": {},
   "source": [
    "And the second one selects from among the options in `sex`, so that we can (for example) look at sex differences separately in each `group`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafda2fe-a1d8-48cb-a852-aa34f558386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "autism_sex_means.loc[1, 1] - autism_sex_means.loc[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8932563-1d90-4011-8b15-324e575f6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "autism_sex_means.loc[2, 1] - autism_sex_means.loc[2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f3d7e-d765-40ac-b6be-dce437ca4f6a",
   "metadata": {},
   "source": [
    "## Combining data\n",
    "\n",
    "Another functionality that Pandas implements that is very useful is the ability to merge different data based on shared variables. For example, the Freesurfer features that we saw above are taken from anatomical scans, and ABIDE also provides some quality information about these anatomical scans: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e6e06-18da-42a5-a4ce-bb176037a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_qc = pd.read_csv(\"/home/jovyan/shared/abide2/abide2_anat_qap.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122fe6a-0234-4dab-aa05-8934eb043f52",
   "metadata": {},
   "source": [
    "Looking at the statistics of these QC data is probably pretty useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca55b3e-1622-44af-ab63-0a4054e42789",
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_qc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed325799-dd97-4bb0-ab5c-8795f9c59455",
   "metadata": {},
   "source": [
    "We notice that there is a lot more data here. This might be because some subjects have more than one entry (for example, attended more than one session). We can cut that down by dropping duplicates on the subject ID column. In most cases, we'd need to verify that this command really is doing the right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c6bb6-7e63-4428-99c7-4032ea622e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_qc = anat_qc.drop_duplicates(\"Sub_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b86fb2-78a8-45cf-9fae-a09bc95b2239",
   "metadata": {},
   "source": [
    "Now let's describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd3d9f-efdb-4ce3-b4af-ce3b81b8932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_qc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875be8d-0f22-4097-a557-b3a499058268",
   "metadata": {},
   "source": [
    "There's still a bit more data here than in the Freesurfer table, and this is something we can explore in a bit more detail. For now, let's move on. This is probably a good time to mention that we can directly visualize data from a DataFrame's `hist` method. We'll look at other visualization methods that take advantage of Pandas later in the week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b5ab1-5828-487a-96e2-3dc7d7424db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_qc[[\"SNR\", \"CNR\"]].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6acc75-0eb3-4bee-8622-1f6e69d69850",
   "metadata": {},
   "source": [
    "Let's say that we'd like to look at the Freesurfer information, but only for subjects that have an SNR larger than 10. One way to do that is to combine the data from the two tables. \n",
    "\n",
    "Before we do that, let's just note that there are few different ways that you could combine tables.\n",
    "\n",
    "We'll go back to much simplified tables, before coming back to do this with the ABIDE data. Imagine we have some more fruit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fad2d8-133e-4381-a52b-580c119fc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_fruit = {\"UID\": [\"a102\", \"a103\", \"o103\", \"b102\"],\n",
    "              \"Kind\": [\"Apple\", \"Apple\", \"Orange\", \"Banana\"], \n",
    "              \"Price\": [0.09, 0.125, 0.66, 3.0],\n",
    "              \"Weight\": [180, 250, 220, 250],\n",
    "              \"Deliciousness\": [3, 7, 10, 5]}\n",
    "\n",
    "another_fruit_table = pd.DataFrame(more_fruit)\n",
    "another_fruit_table = another_fruit_table.set_index(\"UID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34656f6-a5fb-47fc-b4c1-39d2ff84d46c",
   "metadata": {},
   "source": [
    "One way to combine these is to concatenate the tables. This can be useful for cases where more measurements are incrementally added to a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fead935-1a5a-4410-9c4e-44aa7b8290bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([fruit_table, another_fruit_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fccb00-8853-4ec0-805e-49a39d688377",
   "metadata": {},
   "source": [
    "Notice that Pandas is not too confused by the fact that these two tables have different numbers of columns, but it also doesn't automatically recompute the values for the table that doesn't have these added columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862623c8-5eb5-4b23-93c3-cf88781de198",
   "metadata": {},
   "source": [
    "This kind of combination would not be particularly useful for the ABIDE situation, is it? What do you think would happen if you concatenated the `features` and `anat_qc` tables in this way?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31764b3e-9402-4477-b8da-fdfc26e3d17a",
   "metadata": {},
   "source": [
    "A more reasonable thing to do in this case is to *merge* the data. This is because the In a merge, we designate the variable that is used to merge (in databases, this is sometimes known as a \"foreign key\"). Here, we can rely on the fact that both tables have subject identifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a2338-ef82-480b-b740-e60b41a4a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(features, anat_qc, left_on=\"subject\", right_on=\"Sub_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e759fe7-56ad-4513-a822-a1e940d932f8",
   "metadata": {},
   "source": [
    "The resulting table has information from both of the source tables. Note that `pd.merge` has different ways of merging data from different sources. What kinds of variations do you think we need to have for this operation? The `how` key-word argument of the merge function is a way to control different ways of doing this merge. Per default, it takes the strategy called an \"inner\" merge, which preserves only the cases where there is congruence between the keys. This also implies that we'll have the number of subjects of the smaller of the two (1004), dropping those subjects that appear in one table but not the other. This is the strategy that makes sense here, but sometimes you want to keep going with the subjects for whom you don't have data in some columns. In which case, another strategy might make more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99513bf-45ee-4f47-8712-f87a16553636",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1baaac-6a19-4944-a2c0-f2feed396824",
   "metadata": {},
   "source": [
    "Now, we can conduct the comparisons we want (e.g., grouping by `sex` and `group`) directly on the merged data, incorporating information about SNR as a selection variable. Putting together much of what we saw above, we can call: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e2280-3d9d-4d84-a77e-96c184ce0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged[\"SNR\"] > 10].groupby([\"group\", \"sex\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da69bae-d2cb-4ab8-b12e-cfb09170ed5d",
   "metadata": {},
   "source": [
    "## Tidy data\n",
    "\n",
    "A few more words before we wrap up. We saw here operations that we can do with input data using Pandas. This is all pretty elegant, and there's a lot more. But underlying our ability to perform these operations is a secret. The data have to show up looking a very particular way for all this to work. This way is sometimes called \"Tidy data\" after a concept described by the illustrious computational statistician and statistical software pioneer Hadley Wickham. In a paper called simply [\"Tidy data\"](https://vita.had.co.nz/papers/tidy-data.pdf) he describes the details of this idea, but it boils down to the idea that each row is an observation in our dataset and each column should be a variable. So, for example, a datset that has a column named \"Subject_001\" should raise some red flags. This is also something that database people call \"Third normal form\". There are some variations on this (we'll see a bit of these variations in the visualization tutorial), and some nuances (for example, a column called \"is_male\" or \"is_autism\" is much more useful than \"sex\" and \"group\"), but that's the big picture idea. Once everything is nice and tidy, Pandas can do a lot with it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
